---
title: "Bootstrapping the GSS"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    css: "css/font-size.css"
runtime: shiny_prerendered
description: >
  Use bootstrapping to construct confidence intervals and learn how to
  interpret confidence intervals using data from the General Social Survey (GSS). 
---


```{r setup, include=FALSE}
# load packages ----------------------------------------------------------------

library(tidyverse)
library(tidymodels)
library(dsbox)
library(learnr)
library(learnrhash)
library(gradethis)
library(skimr)
# set options for exercises and checking ---------------------------------------
gradethis_setup()
# hide non-exercise code chunks ------------------------------------------------
knitr::opts_chunk$set(echo = FALSE)
```

```{r setup-email-var}
gss16 <- dsbox::gss16 %>% 
  mutate(email = emailmin + (emailhr * 60)) 
```

```{r setup-seed-email-na}
gss16 <- dsbox::gss16 %>% 
  mutate(email = emailmin + (emailhr * 60)) 
set.seed(1234)
```

```{r setup-boot-df-slope, message=FALSE,warning=FALSE}
gss16 <- dsbox::gss16 %>% 
  mutate(email = emailmin + (emailhr * 60)) 
  
set.seed(1234)
boot_df <- gss16 %>%
  specify(email ~ educ) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "slope")
```

```{r setup-boot-df-mean, message=FALSE, warning=FALSE}
gss16 <- dsbox::gss16 %>% 
  mutate(email = emailmin + (emailhr * 60)) 
  
set.seed(1411)
bootmean_df <- gss16 %>%
  specify(response = email) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean")

```


<!---
```{r setup-boot-df-median}
gss16_email <- dsbox::gss16 %>%
  mutate(email = emailmin + (emailhr * 60)) %>%
  filter(!is.na(email))
set.seed(974535)
boot_df_median <- gss16_email %>%
  specify(response = email) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "median")
```

--->

## Introduction

![Photo by Christian Wiediger on Unsplash](images/christian-wiediger-70ku6P7kgmc-unsplash.jpg)


The General Social Survey (GSS) gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviors, and attributes. 
Hundreds of trends have been tracked since 1972. 
In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.

The GSS contains a standard core of demographic, behavioral, and attitudinal questions, plus topics of special interest. 
Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.

In this assignment we analyze data from the 2016 GSS, using it to estimate values of population parameters of interest about US adults.


### Learning goals

- Continue to hone your data wrangling skills.
- Use bootstrapping to construct confidence intervals.
- Interpret confidence intervals in context of the data.

### Packages

In this assignment we will work with the following packages. 
You can load them with the following code block.

```{r load-packages, exercise = TRUE}
library(tidyverse)
library(tidymodels)    
library(dsbox)
library(skimr)
```

```{r load-packages-solution}
library(tidyverse)
library(tidymodels)
library(dsbox)
library(skimr)
```

```{r load-packages-check}
grade_this_code("You've successfully loaded the packages.")
```

## Data

The 2016 GSS dataset is available as part of the `dsbox` package we just loaded. The data frame is called `gss16`.

A description of the variables is shown below.

### Data dictionary

| Variable name    | Description/Question in GSS 
|:--------|:-------------------------------------------------------------
| `harass5`		| "Over the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?"
| `emailmin` 	| Number of minutes spent on email weekly, extra to the hours in emailhrs (e.g. emailmin = 30 for 2.5 hours on email).
| `emailhr` 	| Number of hours spent on email weekly.
| `educ` 		  | Number of years in education.
| `polviews` 	| Political views. Possible answers are Extremely liberal, Liberal, Slightly liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative.
| `advfront`  | Response to the question "Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government." Possible answers are Strongly agree, Agree, Don't know, Disagree and Strongly Disagree
| `snapchat`  | Whether respondent uses Snapchat or not.
| `instagram` | Whether respondent uses Instagram or not.
| `wrkstat`   | Work status.


## Exercises

### Time spent on `email` 

The 2016 GSS asked respondents how many hours and minutes they spend on email weekly. 
The responses to these questions are recorded in the `emailhr` and `emailmin` variables. 
For example, if the response is 2.5 hrs, this would be recorded as `emailhr = 2` and `emailmin = 30`.


For the first exercise, create a new variable called `email` that combines these two variables to reports the number of minutes the respondents spend on email weekly.


```{r email-variable, exercise=TRUE}
gss16 <- gss16 %>%
   ___
```

```{r email-variable-hint-1}
gss16 <- gss16 %>%
  mutate(___)
```

```{r email-variable-hint-2}
gss16 <- gss16 %>%
  mutate(email = ___)
```

```{r email-variable-hint-3}
gss16 <- gss16 %>%
  mutate(email = emailmin + emailhr * 60)
```


### `Email` versus `educ`

Are the number of years of education related to the amount of time people spend on email? Let's first get an overview of these variables  using `skim`. Go ahead and run the code below.

```{r skim-data, exercise = TRUE, exercise.setup = "setup-email-var" }
gss16 %>% skim(email, educ)

```


Make a scatterplot to examine the association between `educ` as explanatory and `email` as the response.

```{r email-educ-plot, exercise=TRUE, exercise.setup = "setup-email-var"}


```

```{r email-educ-plot-hint-1}
ggplot(data = gss16, 
       mapping= = aes(x = ___,
                      y = ___)) 

```


```{r email-educ-plot-hint-2}
ggplot(data = gss16, 
       mapping= = aes(x = educ,
                      y = email)) + 
  geom____() 

```

```{r email-educ-plot-hint-3}
ggplot(data = gss16, 
       mapping= = aes(x = educ,
                      y = email)) + 
  geom_point() +  
  geom_smooth(method = "__")

```


```{r email-educ-plot-hint-4}

ggplot(data = gss16, 
       mapping=aes( x = educ, 
                    y = email)) +
  geom_point() + 
  geom_smooth(method = "lm")

```


Fit a linear model relating `email` as the response variable to `educ` as the explanatory variable. Interpret the estimate of the slope. 

```{r email-educ-fit, exercise=TRUE, exercise.setup = "setup-email-var"}


```


```{r email-educ-fit-hint-1}

model1 <- lm(___ ~ ___, data = ___) 

```


```{r email-educ-fit-hint-2 }

model1 <- lm(email ~ educ, data = gss16) 


```


```{r email-educ-fit-hint-3 }

model1 <- lm(email ~ educ, data = gss16) 

model1 %>% tidy()

```

```{r quiz-estimates}
question("Which statement correctly interprets the estimate of the slope?",
  answer("Associated with an increase of a year of education, we can expect a decrease of 220 minutes in time spent on email, on average"),
  answer("Associated with an increase of a year of education, we can expect an increase of 45.3 minutes in time spent on email, on average",
    correct = TRUE),
  answer(" Associated with an increase of a year of education, we can expect an increase of 45.3 hours in time spent on email, on average"),
  answer("Associated with an increase of one minute spent on email, we can expect an increase of 45.3 years in education, on average"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```



<!--- 
### Filter the data

Next, let's filter the data for only those who have non `NA` entries for `email` and save the resulting data frame as `gss16_email`. 
Do not overwrite the data frame (youâ€™ll need the full data later). 
Instead save the resulting data frame as `gss16_email`.


```{r filter-email, exercise = TRUE, exercise.setup = "setup-email-var"}


```


```{r filter-email-hint-1}
gss16_email <- gss16 %>%
  ___
```

```{r filter-email-hint-2}
gss16_email <- gss16 %>%
  filter(___(email))
```

```{r filter-email-hint-3}
gss16_email <- gss16 %>%
  filter(!is.na(email))
```

--->

### Bootstrap confidence intervals

As we saw in the previous section, there is a positive association between years of education and the time spent on email. For every additional year of education, we can expect the worker will spend an additional 45.3 minutes on email.  

How might this estimate of the slope change if we took a different sample from the same population as `gss16`?
 
In the following exercise, we'll be using the `infer` package to construct the bootstrapped distribution of the slope. 

Since the bootstrapping involves some random sampling, we want some way of essentially defining how the random sampling is done.
For example, this might be done so that if another person runs your R code, they'll produce the same confidence interval as you.

Fortunately, this can be done quite easily by setting a `seed`.
For this tutorial, we'll settle on the rather arbitrary `1234`, but you can use any seed you like in your own assignments.

Use the following code block to set this seed:

```{r set-seed, exercise = TRUE}
set.seed(1234)
```

```{r set-seed-solution}
set.seed(1234)
```

```{r set-seed-check}
grade_this_code("You've set the seed ready for bootstrapping.")
```

### Creating the data frame

When bootstrapping, we first need to create a data frame containing our bootstrapped data - in this case, sample slopes.

There are a few functions we use from the `infer` package in doing this:

- `specify()` is used to specify which columns in our data frame are  the relevant response (and if applicable, explanatory) variables using the formula syntax: response $\sim$ explanatory. 

- `generate()` generates the bootstrap samples.

- And finally, `calculate()` calculates the sample statistic. In this case, we're using the slope, but we could just as easily calculate, say, mean or median etc.


Fill in the blanks in the following code block to create a bootstrapped data frame which contains the slopes 1,000 new samples which are created by resampling the original sample:

```{r create-boot-df, exercise = TRUE, exercise.setup = "setup-email-var"}
boot_df <- gss16 %>%
  filter(!is.na(email), !is.na(educ) ) %>%
  specify(___ ~ ___ ) %>% 
  generate(reps = 1000, type = "___") %>% 
  ___(stat = "___")
```

```{r create-boot-df-hint-1}
boot_df <- gss16 %>%
  filter(!is.na(email), !is.na(educ) ) %>%
  specify(email ~ educ ) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  ___(stat = "___")
```

```{r create-boot-df-hint-2}
boot_df <- gss16 %>%
  filter(!is.na(email), !is.na(educ) ) %>%
  specify(email ~ educ) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "___")
```

```{r create-boot-df-solution}
boot_df <- gss16 %>%
  filter(!is.na(email), !is.na(educ) ) %>%
  specify(email ~ educ) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "slope")
```

```{r create-boot-df-check}
grade_this_code("That's great! You've created the bootstrap data frame.")
```

### Glimpse the bootstrapped data frame

Let's have a quick look at the bootstrapped data frame:

```{r glimpse-boot-df, exercise = TRUE, exercise.setup = "setup-boot-df-slope"}
boot_df
```

Note that each value of the `stat` field is a particular bootstrapped sample slope.

### Visualize the bootstrapped distribution

We can easily plot the distribution of `stat` using `ggplot`. Go ahead and make a histogram of the bootstrapped means in the `boot_df` dataframe. 

```{r visualize_stat, exercise=TRUE, exercise.setup="setup-boot-df-slope"}


```


```{r visualize_stat-solution}

ggplot(data=boot_df, mapping=aes(x = stat))+
  geom_histogram()+
  labs(title="Bootstrapped distribution of slopes")

```


### Find the bootstrap interval

Now we have the `boot_df` data frame, we can construct the bootstrap percentile interval itself by picking out a certain percentage of the center of the distribution of the variable `stat`.
Since we're after a 95% interval, we take the center 95% of the bootstrap distribution, and find the range of these values.
This gives the desired interval.

To find this range, we calculate percentiles so that the central 95% of the distribution is contained within them.

Fill in the blanks in this code block to construct the 95% bootstrap confidence interval for the slope of `educ`

```{r confidence-interval-email, exercise = TRUE, exercise.setup = "setup-boot-df-slope"}
___ %>%
  summarize(lower = quantile(___, ___),
            upper = ___(___, ___))
```

```{r confidence-interval-email-hint-1}
boot_df %>%
  summarize(lower = quantile(___, ___),
            upper = ___(___, ___))
```

```{r confidence-interval-email-hint-2}
boot_df %>%
  summarize(lower = quantile(stat, ___),
            upper = ___(___, ___))
```

```{r confidence-interval-email-hint-3}
boot_df %>%
  summarize(lower = quantile(stat, 0.025),
            upper = ___(___, ___))
```

```{r confidence-interval-email-solution}
boot_df %>%
  summarize(lower = quantile(stat, 0.025),
            upper = quantile(stat, 0.975))
```


```{r confidence-interval-email-check}
grade_this({
  if(identical(floor(as.numeric(.result$lower[1])), 34) & identical(floor(as.numeric(.result$upper[1])), 56)) {
    pass("That is the 95% bootstrap percentile interval for the slope of educ.")
  }
  if(identical(floor(as.numeric(.result$lower[1])), 36) & identical(floor(as.numeric(.result$upper[1])), 54)) {
    fail("It looks like you've calculated a 90% confidence interval. Remember that to pick out the central 95% of the distribution, we need to discard the most extreme 2.5% at each side.")
  }
  fail("Not quite. Take a look at the hints if you need some help.")
})
```

Would you expect a 99% bootstrap interval to be wider or narrower than the interval you calculated above?

```{r quiz-confidence}
question("Which statement is correct?",
  answer("The 99% confidence interval will be narrower, because we have to allow for less variation in order to be 99% accurate"),
  answer("The 99% confidence interval will be wider, because we need to allow for more variation in order to be more certain that any given mean will lie within the interval",
    correct = TRUE),
  answer("We really can't say as it will depend on the distribution"),
  answer("The 95% confidence interval will be wider, because we can allow for more variation in order to be 95% accurate"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

Using the bootstrap distribution in `boot_df` from the previous exercise, calculate a 99%
bootstrap percentile interval for the slope of `educ`.

```{r confidence-99-email, exercise = TRUE, exercise.setup = "setup-boot-df-slope"}
boot_df %>% 
   summarise( lower = ___(___, ___), 
              upper = ___(___, ___ ))
```

```{r confidence-99-email-hint-1}
Look at the previous question for help!
```


```{r confidence-99-email-hint-2}
boot_df %>%
  summarize(lower = quantile(stat, 0.005),
            upper = quantile(___, ___))
```

```{r confidence-99-email-solution}
boot_df %>%
  summarize(lower = quantile(stat, 0.005),
            upper = quantile(stat, 0.995))
```

```{r confidence-99-email-check}
grade_this({
  if(identical(floor(as.numeric(.result$lower[1])), 31) & identical(floor(as.numeric(.result$upper[1])), 59) ) {
    pass("You have calculated the 99% confidence interval correctly!")
  }
  if(identical(floor(as.numeric(.result$lower[1])), 32) & identical(floor(as.numeric(.result$upper[1])), 58)) {
    fail("It looks like you've calculated a 98% confidence interval. Remember that to pick out the central 99% of the distribution, we need to discard the most extreme 0.5% at each side.")
  }
  fail("Not quite. Take a look at the hints if you need some help.")
})
```


Let's practice calculating one more confidence interval. Go ahead and calculate the 90% confidence interval for the slope of `educ`. 

```{r confidence-90-email, exercise = TRUE, exercise.setup = "setup-boot-df-slope"}
boot_df %>% 
   summarise( lower = ___(___, ___), 
              upper = ___(___, ___ ))
```

```{r confidence-90-email-solution}
boot_df %>%
  summarize(lower = quantile(stat, 0.05),
            upper = quantile(stat, 0.95))
```

```{r confidence-90-email-check}
grade_this({
  if(identical(floor(as.numeric(.result$lower[1])), 36) & identical(floor(as.numeric(.result$upper[1])), 54) ) {
    pass("You have calculated the 99% confidence interval correctly!")
  }
  fail("Not quite. Take a look at the hints if you need some help.")
})
```



### Bootstrapping the mean

Bootstrapping is a resampling method which can be used for quantifying the uncertainty of sample values generally.  For example, say instead of studying the relationship between `email` and `educ`, we simply want to know the average (mean) number of minutes American workers spend on email. 

Calculate the mean number of minutes spent on `email` in this sample.

```{r email-mean, exercise=TRUE, exercise.setup="setup-email-var"}

```

```{r email-mean-hint-1}

#don't forget to remove NAs 
```

```{r email-mean-hint-2}

gss16 %>% summarise( mean_email = ___  )
```


```{r email-mean-hint-3}
gss16 %>% summarise(mean_email= mean(email, na.rm=TRUE))
```

Now let's assess the variability in this estimate by bootstrapping 1,000 times. Remember, this means we will draw 1,000 samples each containing `r nrow(gss16)` people who are drawn randomly with replacement from `gss16`. Assuming our sample is representative of the population, we can get a pretty good idea of how estimates will vary from sample to sample by using this technique. 

The function `infer` can be used as before. The only layers that require change are `specify` and `calculate`. 



```{r create-bootmean-df, exercise = TRUE, exercise.setup = "setup-email-var"}
set.seed(1411)

bootmean_df <- gss16 %>%
  specify(response = ___) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "___")
```

```{r create-bootmean-df-hint-1}
bootmean_df <- gss16 %>%
  specify(response = email) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "___")

```

```{r create-bootmean-df-hint-2}
bootmean_df <- gss16 %>%
  specify(response = email) %>% 
  generate(reps = 1000, type = "bootstrap") %>% 
  calculate(stat = "mean")

```

Go ahead and visualize the bootstrapped distribution of the mean number of minutes spent on email. The variability of this distribution is what we are trying to describe. Calculate the 95% bootstrap interval for the mean number of minutes spent on email by American workers. 



```{r mean-plot, exercise = TRUE, exercise.setup = "setup-boot-df-mean"}


```


```{r mean-plot-hint-1}
ggplot(data=bootmean_df, 
       mapping=aes(x = ___))+
  geom____()+
  labs(title="Bootstrapped distribution of the mean number of minutes spent on email")

```

```{r mean-plot-hint-2}
ggplot(data=bootmean_df, mapping=aes(x = stat))+
  geom_histogram(binwidth = 4.4)+
  labs(title="Bootstrapped distribution of the mean number of minutes spent on email")

bootmean_df %>%
  summarize(lower = quantile(stat, 0.025),
            upper = quantile(___, ___))

```


```{r mean-plot-hint-3}
ggplot(data=bootmean_df, mapping=aes(x = stat))+
  geom_histogram(binwidth = 4.4)+
  labs(title="Bootstrapped distribution of the mean number of minutes spent on email")

bootmean_df %>%
  summarize(lower = quantile(stat, 0.025),
            upper = quantile(stat, 0.975))

```


## Wrap Up

That's it! 
You've finished the tutorial on bootstrapping, congratulations!
We hope you enjoyed this exploration. 


```{r context="server"}
learnrhash::encoder_logic(strip_output=TRUE)
```

```{r encode, echo=FALSE}
learnrhash::encoder_ui(ui_after=NULL, ui_before=default_ui(url="https://canvas.uw.edu/courses/1721011/quizzes/1994360") )
```

## Acknowledgements

This tutorial is from Data Science in a Box.